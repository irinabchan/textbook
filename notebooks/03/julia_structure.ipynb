{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIDDEN\n",
    "Base.displaysize() = (5, 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure\n",
    "\n",
    "A dataset's **structure** is a mental representation of our data. For example, we represent data that has a **tabular** structure by arranging data values in rows and columns. In contrast, we represent data that have a **hierarchical** structure, such as a family tree, are represented by allowing a data value to contain other values. Although there are many types of structures that can represent data, giving exhaustive coverage of these structures would likely produce enough content for a few more textbooks. Instead, in this book we will almost always work with data that have a tabular structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A dataset's **file format**, on the other hand, describes how the data files are stored on the computer. For example, a comma-separated values (CSV) file contains data values separated using the comma character (`,`), whereas a plain text file can contain an arbitrary sequences of characters, like the contents of a novel. The format of a data file often describes a structure for the data — a CSV file typically stores data that have a tabular structure. We eventually introduce the following file formats in this book:\n",
    "\n",
    "- Comma-Separated Values (CSV) and Tab-Separated Values (TSV). These files typically contain data with tabular structure. In these files, each row represents a record; data values are delimited by a comma character (`,`) for CSV or a tab character (`\\t`) for TSV. The first line of these files usually contains the names of the data's columns.\n",
    "- JavaScript Object Format (JSON) is a common data format used for communication by web servers. JSON files have a hierarchical structure with keys and values similar to a Julia dictionary.\n",
    "- eXtensible Markup Language (XML) and HyperText Markup Language (HTML) are common data formats for storing documents on the Internet. Like JSON, these files also contain data in a hierarchical, key-value format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a wealth of tools for working with data stored in various formats. In this book, however, we will almost always manipulate data so that we can represent them using a table. Why restrict ourselves in this way? First, much research has studied how to best store and manipulate data tables. This has resulted in stable and efficient tools for working with tables. Second, data in a tabular format are close cousins of matrices, the mathematical objects of the immensely rich field of linear algebra. Finally, data tables are very common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Shell and Command-line Tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nearly all computers provide access to a **shell interpreter**, such as `sh` or `bash`. Like the Julia interpreter, shell interpreters allow users to run code and view its output. Unlike the Julia interpreter, shell interpreters typically perform operations on the computer and its files. Shell interpreters have their own language, syntax, and built-in commands.\n",
    "\n",
    "We use the term **command-line interface (CLI) tools** to refer to the commands available in the shell interpreter. Although we only cover a few useful CLI tools in this section, there are a variety of CLI tools that enable all sorts of useful operations on the computer.\n",
    "\n",
    "**Note:** all CLI tools we cover in this book are specific to the `sh` shell interpreter, the default interpreter for Jupyter installations on MacOS and Linux systems at the time of writing. Notebooks launched on Data 100's JupyterHub will also use the `sh` shell interpreter. Windows systems have a different interpreter and the commands shown in the book may not run on Windows, although Windows gives access to a `sh` interpreter through its Linux Subsystem.\n",
    "\n",
    "Commonly, we open a terminal program to start a shell interpreter. Jupyter notebooks, however, provide a convenience: if a line of code is prefixed with the `;` character, the line will go directly to the system's shell interpreter. For example, the `ls` command lists the files in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babynames.csv\n",
      "julia_intro.ipynb\n",
      "julia_structure.ipynb\n",
      "others\n",
      "pandas_apply_strings_plotting.ipynb\n",
      "pandas_apply_strings_plotting.md\n",
      "pandas_apply_strings_plotting_files\n",
      "pandas_grouping_pivoting.ipynb\n",
      "pandas_grouping_pivoting.md\n",
      "pandas_indexes.ipynb\n",
      "pandas_indexes.md\n",
      "pandas_intro.ipynb\n",
      "pandas_intro.md\n",
      "pandas_structure.ipynb\n",
      "pandas_structure.md\n"
     ]
    }
   ],
   "source": [
    ";ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the line above, Jupyter runs the `ls` command through the `sh` shell interpreter and displays the results of the command in the notebook.\n",
    "\n",
    "CLI tools like `ls` often take in an **argument**, similar to how Julia functions take in arguments. In `sh`, however, we wrap arguments with spaces, not parentheses. Calling `ls` with a folder as an argument shows all the files in the folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babies.data\n",
      "text.txt\n"
     ]
    }
   ],
   "source": [
    ";ls others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we locate a file of interest, we use other command-line tools to check structure. The `head` command displays the first few lines of a file and is very useful for peeking at a file's contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bwt gestation parity age height weight smoke\n",
      "120 284   0  27  62 100   0\n",
      "113 282   0  33  64 135   0\n",
      "128 279   0  28  64 115   1\n",
      "123 999   0  36  69 190   0\n",
      "108 282   0  23  67 125   1\n",
      "136 286   0  25  62  93   0\n",
      "138 244   0  33  62 178   0\n",
      "132 245   0  23  65 140   0\n",
      "120 289   0  25  62 125   0\n"
     ]
    }
   ],
   "source": [
    ";head others/babies.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By default, `head` displays the first 10 lines of a file. To display the last 10 lines, we use the `tail` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "103 278   0  30  60  87   1\n",
      "118 276   0  34  64 116   0\n",
      "127 290   0  27  65 121   0\n",
      "132 270   0  27  65 126   0\n",
      "113 275   1  27  60 100   0\n",
      "128 265   0  24  67 120   0\n",
      "130 291   0  30  65 150   1\n",
      "125 281   1  21  65 110   0\n",
      "117 297   0  38  65 129   0\n",
      "\n"
     ]
    }
   ],
   "source": [
    ";tail others/babies.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the entire file's contents using the `cat` command. Take care when using this command, however, as printing a large file can cause the browser to crash."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"city\",\"zip\",\"street\"\n",
      "\"Alameda\",\"94501\",\"1220 Broadway\"\n",
      "\"Alameda\",\"94501\",\"429 Fair Haven Road\"\n",
      "\"Alameda\",\"94501\",\"2804 Fernside Boulevard\"\n",
      "\"Alameda\",\"94501\",\"1316 Grove Street\""
     ]
    }
   ],
   "source": [
    ";cat others/text.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In many cases, using `head` and `tail` alone gives us a sense of the file structure. For example, we can see that the `babynames.csv` file uses the CSV file format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name,Sex,Count,Year\n",
      "Mary,F,9217,1884\n",
      "Anna,F,3860,1884\n",
      "Emma,F,2587,1884\n",
      "Elizabeth,F,2549,1884\n",
      "Minnie,F,2243,1884\n",
      "Margaret,F,2142,1884\n",
      "Ida,F,1882,1884\n",
      "Clara,F,1852,1884\n",
      "Bertha,F,1789,1884\n"
     ]
    }
   ],
   "source": [
    ";head babynames.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can easily read in CSV files using `DataFrames` using the `CSV.read` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>Name</th><th>Sex</th><th>Count</th><th>Year</th></tr><tr><th></th><th>String</th><th>String</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>1,891,894 rows × 4 columns</p><tr><th>1</th><td>Mary</td><td>F</td><td>9217</td><td>1884</td></tr><tr><th>2</th><td>Anna</td><td>F</td><td>3860</td><td>1884</td></tr><tr><th>3</th><td>Emma</td><td>F</td><td>2587</td><td>1884</td></tr><tr><th>4</th><td>Elizabeth</td><td>F</td><td>2549</td><td>1884</td></tr><tr><th>5</th><td>Minnie</td><td>F</td><td>2243</td><td>1884</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|cccc}\n",
       "\t& Name & Sex & Count & Year\\\\\n",
       "\t\\hline\n",
       "\t& String & String & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & Mary & F & 9217 & 1884 \\\\\n",
       "\t2 & Anna & F & 3860 & 1884 \\\\\n",
       "\t3 & Emma & F & 2587 & 1884 \\\\\n",
       "\t4 & Elizabeth & F & 2549 & 1884 \\\\\n",
       "\t5 & Minnie & F & 2243 & 1884 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "1891894×4 DataFrame\n"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "\n",
    "CSV.read(\"babynames.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filesizes\n",
    "\n",
    "Notice that reading in the `babynames.csv` file results in a DataFrame with nearly two million rows. As of this writing, all computers have finite limits on computing power. You have likely encountered these limits firsthand if your computer has slowed down from having too many applications opened at once. We often want to make sure that we do not exceed the computer's limits while working with data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most situations, we begin data analysis with datasets downloaded from the Internet. These files reside on the computer's **disk storage**. In order to use Julia to explore and manipulate the data, however, we need to read the data into the computer's **memory**, also known as random access memory (RAM). All Julia code requires the use of RAM, no matter how short the code is.\n",
    "\n",
    "Unfortunately, a computer's RAM is typically much smaller than a computer's disk storage. For example, one computer model released in 2018 had 32 times more disk storage than RAM. This means that data files can often be much bigger than what is feasible to read into memory.\n",
    "\n",
    "Both disk storage and RAM capacity are measured in terms of **bytes**. Roughly speaking, each character in a text file adds one byte to the file's size. For example, a file containing the following text has 177 characters and thus takes up 177 bytes of disk space.\n",
    "\n",
    "    \"city\",\"zip\",\"street\"\n",
    "    \"Alameda\",\"94501\",\"1220 Broadway\"\n",
    "    \"Alameda\",\"94501\",\"429 Fair Haven Road\"\n",
    "    \"Alameda\",\"94501\",\"2804 Fernside Boulevard\"\n",
    "    \"Alameda\",\"94501\",\"1316 Grove Street\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, many of the datasets we work with today contain many characters. To succinctly describe the sizes of larger files, we use the following prefixes:\n",
    "\n",
    "| Multiple | Notation | Number of Bytes    |\n",
    "| -------- | -------- | ------------------ |\n",
    "| Kibibyte | KiB      | 1024 = $ 2^{10} $  |\n",
    "| Mebibyte | MiB      | 1024² = $ 2^{20} $ |\n",
    "| Gibibyte | GiB      | 1024³ = $ 2^{30} $ |\n",
    "| Tebibyte | TiB      | 1024⁴ = $ 2^{40} $ |\n",
    "| Pebibyte | PiB      | 1024⁵ = $ 2^{50} $ |\n",
    "\n",
    "For example, a file containing 52428800 characters takes up 52428800 bytes = 50 mebibytes = 50 MiB on disk.\n",
    "\n",
    "Why use multiples of 1024 instead of simple multiples of 1000 for these prefixes? This is a historical result of the fact that nearly all computers use a binary number scheme where powers of 2 are simpler to represent. You will also see the typical SI prefixes used to describe size — kilobytes, megabytes, and gigabytes, for example. Unfortunately, these prefixes are used inconsistently. Sometimes a kilobyte refers to 1000 bytes; other times, a kilobyte refers to 1024 bytes. To avoid confusion, we will stick to kibi-, mebi-, and gibibytes which clearly represent multiples of 1024."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When Is It Safe To Read In a File?**\n",
    "\n",
    "Many computers have much more disk storage than available memory. It is not uncommon to have a data file happily stored on a computer that will overflow the computer's memory if we attempt to manipulate it with a program, including Julia programs. In order to begin a data analysis, we often begin by making sure the files we will work with are of manageable size. To accomplish this, we use the command-line interface (CLI) tools `ls` and `du`.\n",
    "\n",
    "Recall that `ls` shows the files within a folder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "babies.data\n",
      "text.txt\n"
     ]
    }
   ],
   "source": [
    ";ls others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Command-line tools like `ls` often support **flags** that provide additional options for the user. For example, adding the `-l` flag lists one file per line with additional metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 80\n",
      "-rw-r--r--  1 irinabchan  staff  34654 Sep 14 12:53 babies.data\n",
      "-rw-r--r--  1 irinabchan  staff    177 Sep 14 12:53 text.txt\n"
     ]
    }
   ],
   "source": [
    ";ls -l others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In particular, the fifth column of the listing shows the file size in bytes. For example, we can see that the `babies.data` file takes up `34654` bytes on disk. To make the file sizes more readable, we can use the `-h` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 80\n",
      "-rw-r--r--  1 irinabchan  staff    34K Sep 14 12:53 babies.data\n",
      "-rw-r--r--  1 irinabchan  staff   177B Sep 14 12:53 text.txt\n"
     ]
    }
   ],
   "source": [
    ";ls -l -h others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the `babies.data` file takes up 34 KiB on disk, making it well within the memory capacities of most systems. Although the `babynames.csv` file has nearly 2 million rows, it only takes up 30 MiB of disk storage. Most machines can read in the `babynames.csv` too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 63112\n",
      "-rw-r--r--  1 irinabchan  staff    30M Sep 14 12:53 babynames.csv\n",
      "-rw-r--r--  1 irinabchan  staff   1.7K Oct 17 10:24 julia_intro.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff    17K Oct 17 10:51 julia_structure.ipynb\n",
      "drwxr-xr-x  4 irinabchan  staff   128B Sep 14 12:53 others\n",
      "-rw-r--r--  1 irinabchan  staff   118K Sep 14 12:53 pandas_apply_strings_plotting.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff    14K Oct 14 19:20 pandas_apply_strings_plotting.md\n",
      "drwxr-xr-x  5 irinabchan  staff   160B Sep 14 12:53 pandas_apply_strings_plotting_files\n",
      "-rw-r--r--  1 irinabchan  staff    34K Sep 14 12:53 pandas_grouping_pivoting.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff    17K Oct 14 19:20 pandas_grouping_pivoting.md\n",
      "-rw-r--r--  1 irinabchan  staff    32K Sep 14 12:53 pandas_indexes.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff    15K Oct 14 19:20 pandas_indexes.md\n",
      "-rw-r--r--  1 irinabchan  staff   2.1K Oct 17 10:01 pandas_intro.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff   1.3K Oct 14 19:20 pandas_intro.md\n",
      "-rw-r--r--  1 irinabchan  staff    25K Oct 17 10:50 pandas_structure.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff    17K Oct 14 19:20 pandas_structure.md\n"
     ]
    }
   ],
   "source": [
    ";ls -l -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Folder Sizes**\n",
    "\n",
    "Sometimes we are interested in the total size of a folder instead of individual files. For example, if we have one file of sensor recordings for each month in a year, we might like to see whether we combine all the data into a single DataFrame. Note that `ls` does not calculate folder sizes correctly. Notice `ls` shows that the `others` folder takes up 128 bytes on disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 63112\n",
      "-rw-r--r--  1 irinabchan  staff    30M Sep 14 12:53 babynames.csv\n",
      "-rw-r--r--  1 irinabchan  staff   1.7K Oct 17 10:24 julia_intro.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff    19K Oct 17 10:53 julia_structure.ipynb\n",
      "drwxr-xr-x  4 irinabchan  staff   128B Sep 14 12:53 others\n",
      "-rw-r--r--  1 irinabchan  staff   118K Sep 14 12:53 pandas_apply_strings_plotting.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff    14K Oct 14 19:20 pandas_apply_strings_plotting.md\n",
      "drwxr-xr-x  5 irinabchan  staff   160B Sep 14 12:53 pandas_apply_strings_plotting_files\n",
      "-rw-r--r--  1 irinabchan  staff    34K Sep 14 12:53 pandas_grouping_pivoting.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff    17K Oct 14 19:20 pandas_grouping_pivoting.md\n",
      "-rw-r--r--  1 irinabchan  staff    32K Sep 14 12:53 pandas_indexes.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff    15K Oct 14 19:20 pandas_indexes.md\n",
      "-rw-r--r--  1 irinabchan  staff   2.1K Oct 17 10:01 pandas_intro.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff   1.3K Oct 14 19:20 pandas_intro.md\n",
      "-rw-r--r--  1 irinabchan  staff    25K Oct 17 10:52 pandas_structure.ipynb\n",
      "-rw-r--r--  1 irinabchan  staff    17K Oct 14 19:20 pandas_structure.md\n"
     ]
    }
   ],
   "source": [
    ";ls -l -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the folder itself contains files that are larger than 128 bytes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 80\n",
      "-rw-r--r--  1 irinabchan  staff    34K Sep 14 12:53 babies.data\n",
      "-rw-r--r--  1 irinabchan  staff   177B Sep 14 12:53 text.txt\n"
     ]
    }
   ],
   "source": [
    ";ls -l -h others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To properly calculate the total size of a folder, including files in the folder, we use the `du` (short for disk usage) CLI tool. By default, the `du` tool shows the sizes of folders in its own units called blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\tothers\n"
     ]
    }
   ],
   "source": [
    ";du others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show file sizes in bytes, we add the `-h` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 40K\tothers\n"
     ]
    }
   ],
   "source": [
    ";du -h others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We commonly also add the `-s` flag to `du` to show the file sizes for both files and folders. The asterisk in `others/*` below tells `du` to show the size of every item in the `others/*` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT WORKING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Memory Overhead**\n",
    "\n",
    "As a rule of thumb, reading in a file using `DataFrames` usually requires at least double the available memory as the file size. That is, reading in a 1 GiB file will typically require at least 2 GiB of available memory.\n",
    "\n",
    "Note that memory is shared by all programs running on a computer, including the operating system, web browsers, and yes, Jupyter notebook itself. A computer with 4 GiB total RAM might have only 1 GiB available RAM with many applications running. With 1 GiB available RAM, it is unlikely that `DataFrames` will be able to read in a 1 GiB file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
